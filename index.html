<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Pourtoi WebAR Pose Try‑On</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body { margin: 0; overflow: hidden; }
    video, canvas { position: absolute; top: 0; left: 0; }
    video { width: 100%; height: 100%; object-fit: cover; }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="output"></canvas>

  <script type="module">
    import * as tf from "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.esm.js";
    import * as poseDetection from "https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.7/dist/pose-detection.esm.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("output");
    const ctx = canvas.getContext("2d");

    // ✅ Camera setup
    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
      video.srcObject = stream;
    });

    // ✅ Pose detector
    async function initPose() {
      const detector = await poseDetection.createDetector(
        poseDetection.SupportedModels.MoveNet,
        { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
      );
      console.log("Pose detector ready");

      async function detect() {
        const poses = await detector.estimatePoses(video);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw joints for debug
        poses[0]?.keypoints.forEach(kp => {
          ctx.fillStyle = "red";
          ctx.beginPath();
          ctx.arc(kp.x, kp.y, 5, 0, 2 * Math.PI);
          ctx.fill();
        });

        requestAnimationFrame(detect);
      }
      detect();
    }
    initPose();
  </script>
</body>
</html>
